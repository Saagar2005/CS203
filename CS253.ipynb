{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN55esJUUiCW6hPlvW+jBxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saagar2005/CS203/blob/main/CS253.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NIKoLr5M73Bw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "7-y0Dc4m78Cq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.drop(['ID','Candidate','Constituency ∇'],axis = 1, inplace = True)\n",
        "test_data.drop(['ID','Candidate','Constituency ∇'],axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "t6tye-UK7_Lc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_numeric(amount_str):\n",
        "    multiplier = 1\n",
        "    if 'Lac+' in amount_str:\n",
        "        multiplier = 10 ** 5\n",
        "    elif 'Crore+' in amount_str:\n",
        "        multiplier = 10 ** 7\n",
        "    elif 'Thou+' in amount_str:\n",
        "        multiplier = 1000\n",
        "\n",
        "    numeric_part = int(amount_str.split()[0])\n",
        "\n",
        "    return numeric_part * multiplier"
      ],
      "metadata": {
        "id": "hmS5Saji8Cpo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Total Assets'] = train_data['Total Assets'].apply(convert_to_numeric)\n",
        "train_data['Liabilities'] = train_data['Liabilities'].apply(convert_to_numeric)\n",
        "test_data['Total Assets'] = test_data['Total Assets'].apply(convert_to_numeric)\n",
        "test_data['Liabilities'] = test_data['Liabilities'].apply(convert_to_numeric)"
      ],
      "metadata": {
        "id": "Cx-BB_Ef8G3K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "party_label_encoder = LabelEncoder()\n",
        "train_data['Party'] = party_label_encoder.fit_transform(train_data['Party'])\n",
        "test_data['Party'] = party_label_encoder.transform(test_data['Party'])"
      ],
      "metadata": {
        "id": "Neg7rjWM8KxY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_label_encoder = LabelEncoder()\n",
        "\n",
        "train_data['state'] = state_label_encoder.fit_transform(train_data['state'])\n",
        "test_data['state'] = state_label_encoder.transform(test_data['state'])"
      ],
      "metadata": {
        "id": "KRaCm6OZ8RK9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "education_order = ['Literate','5th Pass','8th Pass','10th Pass','12th Pass','Graduate','Graduate Professional','Post Graduate','Doctorate','Others']\n",
        "ordinal_encoder = OrdinalEncoder(categories=[education_order])\n",
        "train_data['Education'] = ordinal_encoder.fit_transform(train_data[['Education']])"
      ],
      "metadata": {
        "id": "SNeOP1-i8ZLs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(train_data['Liabilities'], train_data['Total Assets'], train_data['Education'], c='r', marker='o')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Criminal Case')\n",
        "ax.set_ylabel('Total Assets')\n",
        "ax.set_zlabel('Education')\n",
        "ax.set_title('3D Scatter Plot')\n",
        "\n",
        "# Optionally, use Seaborn for styling\n",
        "sns.set(style=\"whitegrid\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "qmf-sCZ5BYYR",
        "outputId": "12c3154a-14cd-43e2-d140-c80b394d49d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import matplotlib.pyplot as plt\\nfrom mpl_toolkits.mplot3d import Axes3D\\nimport seaborn as sns\\n%matplotlib inline\\n\\nfig = plt.figure()\\nax = fig.add_subplot(111, projection=\\'3d\\')\\n\\nax.scatter(train_data[\\'Liabilities\\'], train_data[\\'Total Assets\\'], train_data[\\'Education\\'], c=\\'r\\', marker=\\'o\\')\\n\\n# Set labels and title\\nax.set_xlabel(\\'Criminal Case\\')\\nax.set_ylabel(\\'Total Assets\\')\\nax.set_zlabel(\\'Education\\')\\nax.set_title(\\'3D Scatter Plot\\')\\n\\n# Optionally, use Seaborn for styling\\nsns.set(style=\"whitegrid\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train_data['Education']\n",
        "train_X = train_data.drop(['Education'], axis = 1)"
      ],
      "metadata": {
        "id": "1dYH21_s8e9O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2)"
      ],
      "metadata": {
        "id": "6CwbzHq-8iaw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define the candidate kernels and their hyperparameters\n",
        "kernels = [\n",
        "    1.0 * RBF(1.0),\n",
        "    1.0 * Matern(length_scale=1.0, nu=1.5),\n",
        "    1.0 * WhiteKernel(noise_level=1.0)\n",
        "]\n",
        "\n",
        "# Create a Gaussian process classifier\n",
        "gpc = GaussianProcessClassifier()\n",
        "\n",
        "# Set up the parameter grid for grid search\n",
        "param_grid = {'kernel': kernels}\n",
        "\n",
        "# Perform grid search with cross-validation to find the best kernel\n",
        "grid_search = GridSearchCV(gpc, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best kernel and its hyperparameters\n",
        "best_kernel = grid_search.best_estimator_.kernel_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Fit the GPC with the best kernel and hyperparameters\n",
        "best_gpc = GaussianProcessClassifier(kernel=best_kernel).fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the F1 score on the test set\n",
        "y_pred = best_gpc.predict(X_test)\n",
        "f1_score = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Kernel: {best_kernel}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTmzskqM9AA8",
        "outputId": "eaec753f-d5d2-4cdc-acc5-62ca664ace1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import f1_score\n",
        "\n",
        "#f1 = f1_score(y_test, predictions, average='weighted')\n",
        "#f1"
      ],
      "metadata": {
        "id": "9y2ISccS9vzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}